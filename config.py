# config.py
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
PROJECT_ROOT = Path(__file__).parent

# ìˆ˜ì§‘í•  í‚¤ì›Œë“œ
KEYWORDS = [
    "bulk", "handy", "handymax", "supramax", "panamax", "capesize",
    "bulker", "dry bulk", "bulk carrier", "steel", "iron ore", "coal", "grain",
    "cargo", "commodity", "freight", "charter", "bdi", "baltic", "tonnage",
    "vessel", "shipping", "maritime", "port", "terminal", "rates", "index", "market",
    "demand", "supply", "ë²Œí¬", "ì² ê°•", "í™”ë¬¼", "ì„ ë°•", "í•´ìš´"
]

# ìˆ˜ì§‘ ì›¹ì‚¬ì´íŠ¸ URL
TARGET_URLS = {
    "tradewinds_latest": "https://www.tradewindsnews.com/latest",
    "tradewinds_bulkers": "https://www.tradewindsnews.com/bulkers",
    "freightwaves_bulkers": "https://www.freightwaves.com/news/tag/dry-bulk-shipping",
    # "hellenic_dry_bulk": "https://www.hellenicshippingnews.com/category/dry-bulk/",
    # "seatrade_dry_cargo": "https://www.seatrade-maritime.com/dry-cargo"
}

# í¬ë¡¤ë§ ì„¤ì •
MAX_ARTICLES_PER_DAY = int(os.getenv("MAX_ARTICLES_PER_DAY", 50))
CRAWL_DELAY = float(os.getenv("CRAWL_DELAY", 1.0))  # ìš”ì²­ ê°„ ë”œë ˆì´(ì´ˆ)
REQUEST_TIMEOUT = int(os.getenv("REQUEST_TIMEOUT", 10))  # ìš”ì²­ íƒ€ì„ì•„ì›ƒ(ì´ˆ)

# ìˆ˜ì§‘ ê¸°ê°„
DATE_RANGE = ("2025-08-01", "2025-08-04")

# ìš”ì²­ í—¤ë” ì„¤ì • (ë´‡ ì°¨ë‹¨ ë°©ì§€)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}

# OpenAI ì„¤ì •
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
OPENAI_TEMPERATURE = float(os.getenv("OPENAI_TEMPERATURE", 0.2))
OPENAI_MAX_TOKENS = int(os.getenv("OPENAI_MAX_TOKENS", 1000))

# ì„ë² ë”© ì„¤ì •
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
EMBEDDING_DIMENSIONS = int(os.getenv("EMBEDDING_DIMENSIONS", 1536))

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
DATA_DIR = PROJECT_ROOT / "data"
LOGS_DIR = PROJECT_ROOT / "logs"
VECTOR_STORE_DIR = PROJECT_ROOT / "vector_store"

# íŒŒì¼ëª…
CRAWLED_ARTICLES_FILE = DATA_DIR / "crawled_articles.json"
ANALYZED_ARTICLES_FILE = DATA_DIR / "analyzed_articles.json"
FAISS_INDEX_FILE = VECTOR_STORE_DIR / "faiss.index"
METADATA_FILE = VECTOR_STORE_DIR / "metadata.jsonl"

# ë¡œê¹… ì„¤ì •
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# ê²€ìƒ‰ ì„¤ì •
DEFAULT_TOP_K = int(os.getenv("DEFAULT_TOP_K", 5))
MAX_SEARCH_RESULTS = int(os.getenv("MAX_SEARCH_RESULTS", 20))

# Streamlit ì„¤ì •
STREAMLIT_PAGE_TITLE = "í•´ìš´Â·ì² ê°• GPT Assistant"
STREAMLIT_PAGE_ICON = "ğŸš¢"
STREAMLIT_LAYOUT = "wide"

# ì¬ì‹œë„ ì„¤ì •
MAX_RETRIES = int(os.getenv("MAX_RETRIES", 3))
RETRY_DELAY = float(os.getenv("RETRY_DELAY", 2.0))

def ensure_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    directories = [DATA_DIR, LOGS_DIR, VECTOR_STORE_DIR]
    for directory in directories:
        directory.mkdir(parents=True, exist_ok=True)

# ì´ˆê¸°í™”ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
ensure_directories()