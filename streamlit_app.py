# streamlit_app.py (ì™„ì „ ê°œì„  ë²„ì „)
import streamlit as st
import pandas as pd
import json
import time
import difflib
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from dotenv import load_dotenv
from vector_store import search_articles, META_PATH
from rag_chain import build_answer

# ---------- í˜ì´ì§€ ì„¤ì • ----------
st.set_page_config(
    page_title="í•´ìš´Â·ì² ê°• GPT Assistant",
    page_icon="ğŸš¢",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ----------
@st.cache_data(ttl=3600, show_spinner=False)
def safe_json_loads(json_str: str) -> Dict:
    """ì•ˆì „í•œ JSON íŒŒì‹±"""
    try:
        if isinstance(json_str, str):
            return json.loads(json_str)
        return json_str if isinstance(json_str, dict) else {}
    except:
        return {}

@st.cache_data(ttl=1800, show_spinner=False)
def load_and_clean_metadata() -> pd.DataFrame:
    """ë©”íƒ€ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ì •ë¦¬ (ìºì‹±)"""
    if not META_PATH.exists():
        return pd.DataFrame()

    rows = []
    failed_count = 0
    
    try:
        with open(META_PATH, 'r', encoding='utf-8') as f:
            for line_num, raw_line in enumerate(f, 1):
                raw_line = raw_line.strip()
                if not raw_line:
                    continue
                    
                try:
                    data = json.loads(raw_line)
                    if not isinstance(data, dict):
                        continue
                    
                    # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                    if not data.get('title') or not data.get('summary'):
                        continue
                    
                    # None ê°’ë“¤ì„ ì ì ˆí•œ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³€í™˜
                    cleaned_data = {
                        'title': str(data.get('title', '')).strip(),
                        'summary': str(data.get('summary', '')).strip(),
                        'date': data.get('date', datetime.now().strftime('%Y-%m-%d')),
                        'source': str(data.get('source', 'Unknown')),
                        'source_url': str(data.get('source_url', '')),
                        'category': data.get('category', []) if isinstance(data.get('category'), list) else [],
                        'assigned_group': data.get('assigned_group', []) if isinstance(data.get('assigned_group'), list) else [],
                        'events': data.get('events', []) if isinstance(data.get('events'), list) else []
                    }
                    
                    # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ 'None' ë¬¸ìì—´ í•„í„°ë§
                    if (cleaned_data['title'] in ['', 'None', 'none'] or 
                        cleaned_data['summary'] in ['', 'None', 'none']):
                        continue
                    
                    rows.append(cleaned_data)
                    
                except json.JSONDecodeError:
                    failed_count += 1
                    continue
                except Exception:
                    failed_count += 1
                    continue
    
    except Exception as e:
        st.error(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return pd.DataFrame()
    
    if not rows:
        return pd.DataFrame()
    
    df = pd.DataFrame(rows)
    
    # ë‚ ì§œ ì»¬ëŸ¼ ì •ë¦¬
    df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date
    df = df.dropna(subset=['date'])
    
    if failed_count > 0:
        st.info(f"ğŸ“Š ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df)}ê°œ ì„±ê³µ, {failed_count}ê°œ ìŠ¤í‚µ")
    
    return df

def smart_deduplicate(df: pd.DataFrame, similarity_threshold: float = 0.85) -> pd.DataFrame:
    """ì§€ëŠ¥í˜• ì¤‘ë³µ ì œê±°"""
    if df.empty:
        return df
    
    original_count = len(df)
    
    # 1ë‹¨ê³„: ì •í™•í•œ ì œëª© ì¤‘ë³µ ì œê±°
    df_clean = df.copy()
    df_clean['title_normalized'] = df_clean['title'].str.lower().str.strip()
    df_clean = df_clean.drop_duplicates(subset=['title_normalized'], keep='first')
    
    # 2ë‹¨ê³„: ìœ ì‚¬í•œ ì œëª© ì œê±° (ì„ íƒì )
    if similarity_threshold > 0:
        to_remove = set()
        titles = df_clean['title_normalized'].tolist()
        
        for i in range(len(titles)):
            if i in to_remove:
                continue
            for j in range(i + 1, len(titles)):
                if j in to_remove:
                    continue
                
                similarity = difflib.SequenceMatcher(None, titles[i], titles[j]).ratio()
                if similarity >= similarity_threshold:
                    # ë” ê¸´ ì œëª©ì„ ìœ ì§€
                    if len(titles[i]) >= len(titles[j]):
                        to_remove.add(j)
                    else:
                        to_remove.add(i)
                        break
        
        if to_remove:
            df_clean = df_clean.drop(df_clean.index[list(to_remove)])
    
    # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
    df_result = df_clean.drop('title_normalized', axis=1).reset_index(drop=True)
    
    removed_count = original_count - len(df_result)
    if removed_count > 0:
        st.info(f"ğŸ”„ ì¤‘ë³µ ì œê±°: {removed_count}ê°œ ì œê±° ({original_count} â†’ {len(df_result)})")
    
    return df_result

@st.cache_data(ttl=3600, show_spinner=False)
def translate_batch_optimized(texts: List[str], target_lang: str = 'ko') -> List[str]:
    """ìµœì í™”ëœ ë°°ì¹˜ ë²ˆì—­"""
    if not texts:
        return []
    
    # ì´ë¯¸ í•œê¸€ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ëŠ” ë²ˆì—­í•˜ì§€ ì•ŠìŒ
    texts_to_translate = []
    original_indices = []
    results = [''] * len(texts)
    
    for i, text in enumerate(texts):
        if not text or pd.isna(text):
            results[i] = text
            continue
            
        # í•œê¸€ í¬í•¨ ì—¬ë¶€ ì²´í¬
        has_korean = any('\uAC00' <= char <= '\uD7A3' for char in str(text))
        if has_korean:
            results[i] = text
            continue
        
        texts_to_translate.append(str(text))
        original_indices.append(i)
    
    if not texts_to_translate:
        return results
    
    try:
        from openai import OpenAI
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # ë°°ì¹˜ í¬ê¸° ì œí•œ (í† í° ì œí•œ ê³ ë ¤)
        batch_size = 10
        translated_results = []
        
        for i in range(0, len(texts_to_translate), batch_size):
            batch = texts_to_translate[i:i + batch_size]
            batch_text = "\n---SEP---\n".join(batch)
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": """í•´ìš´/ë¬¼ë¥˜ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. 
                        ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”.
                        ---SEP---ë¡œ êµ¬ë¶„ëœ ê° í…ìŠ¤íŠ¸ë¥¼ ê°™ì€ êµ¬ë¶„ìë¡œ ë‚˜ëˆ„ì–´ ë²ˆì—­í•˜ì„¸ìš”.
                        ì „ë¬¸ ìš©ì–´ëŠ” ì •í™•íˆ ë²ˆì—­í•˜ë˜ ì½ê¸° ì‰½ê²Œ ì˜ì—­í•˜ì„¸ìš”."""
                    },
                    {"role": "user", "content": f"ë²ˆì—­:\n\n{batch_text}"}
                ],
                temperature=0.2,
                max_tokens=2000
            )
            
            translated_batch = response.choices[0].message.content.strip()
            translated_list = translated_batch.split("---SEP---")
            
            # ê²°ê³¼ ê°œìˆ˜ê°€ ë§ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
            if len(translated_list) != len(batch):
                translated_results.extend(batch)
            else:
                translated_results.extend([t.strip() for t in translated_list])
        
        # ê²°ê³¼ ë³‘í•©
        for i, translated in enumerate(translated_results):
            if i < len(original_indices):
                results[original_indices[i]] = translated
        
        return results
        
    except Exception as e:
        st.warning(f"ë²ˆì—­ ì˜¤ë¥˜: {e}")
        return texts

def apply_translation(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:
    """ë°ì´í„°í”„ë ˆì„ì— ë²ˆì—­ ì ìš©"""
    if df.empty:
        return df
    
    df_translated = df.copy()
    
    for column in columns:
        if column not in df_translated.columns:
            continue
        
        with st.spinner(f"ğŸŒ {column} ë²ˆì—­ ì¤‘..."):
            texts = df_translated[column].tolist()
            translated_texts = translate_batch_optimized(texts)
            
            # ë²ˆì—­ ê²°ê³¼ ì €ì¥
            df_translated[f'{column}_en'] = df_translated[column]
            df_translated[f'{column}_ko'] = translated_texts
            df_translated[column] = translated_texts  # ê¸°ë³¸ì€ í•œêµ­ì–´
    
    return df_translated

def get_valid_filter_options(df: pd.DataFrame) -> Tuple[List[str], List[str]]:
    """ìœ íš¨í•œ í•„í„° ì˜µì…˜ ì¶”ì¶œ"""
    valid_categories = set()
    valid_events = set()
    
    if df.empty:
        return [], []
    
    # í•´ìš´ ê´€ë ¨ í‚¤ì›Œë“œ
    shipping_keywords = {
        'handy', 'handymax', 'supramax', 'panamax', 'capesize',
        'bulker', 'container', 'steel', 'iron ore', 'coal', 'grain',
        'freight', 'rates', 'bdi', 'scfi', 'baltic', 'shipping',
        'maritime', 'port', 'cargo', 'demand', 'supply', 'tonnage'
    }
    
    for _, row in df.iterrows():
        # ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
        categories = row.get('category', [])
        if isinstance(categories, list):
            for cat in categories:
                if isinstance(cat, str) and cat.strip():
                    cat_lower = cat.lower().strip()
                    if any(keyword in cat_lower for keyword in shipping_keywords):
                        valid_categories.add(cat.strip())
        
        # ì´ë²¤íŠ¸ ì²˜ë¦¬
        events = row.get('events', [])
        if isinstance(events, list):
            for event in events:
                if isinstance(event, str) and len(event.strip()) > 2:
                    event_clean = event.strip()
                    # ì˜ë¯¸ìˆëŠ” ì´ë²¤íŠ¸ë§Œ í•„í„°ë§
                    if any(keyword in event_clean.lower() for keyword in ['ìš´ì„', 'ê¸‰ë“±', 'í•˜ë½', 'ì¦ê°€', 'ê°ì†Œ', 'rate', 'surge', 'drop']):
                        valid_events.add(event_clean)
    
    return sorted(list(valid_categories)), sorted(list(valid_events))

def apply_filters(df: pd.DataFrame, filters: Dict) -> pd.DataFrame:
    """í•„í„° ì ìš©"""
    if df.empty:
        return df
    
    filtered_df = df.copy()
    
    # ë‚ ì§œ í•„í„°
    if filters.get('date_range') and len(filters['date_range']) == 2:
        start_date, end_date = filters['date_range']
        filtered_df = filtered_df[
            (filtered_df['date'] >= start_date) & 
            (filtered_df['date'] <= end_date)
        ]
    
    # ê·¸ë£¹ í•„í„°
    if filters.get('groups'):
        filtered_df = filtered_df[filtered_df['assigned_group'].apply(
            lambda groups: isinstance(groups, list) and 
                          any(group in filters['groups'] for group in groups)
        )]
    
    # ì¹´í…Œê³ ë¦¬ í•„í„°
    if filters.get('categories'):
        filtered_df = filtered_df[filtered_df['category'].apply(
            lambda cats: isinstance(cats, list) and 
                        any(cat in filters['categories'] for cat in cats)
        )]
    
    # ì´ë²¤íŠ¸ í•„í„°
    if filters.get('events'):
        filtered_df = filtered_df[filtered_df['events'].apply(
            lambda events: isinstance(events, list) and 
                          any(event in filters['events'] for event in events)
        )]
    
    return filtered_df

def display_article_cards(df: pd.DataFrame, translation_mode: str = "í•œêµ­ì–´", limit: int = 25):
    """ê¸°ì‚¬ ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ"""
    for idx, row in df.head(limit).iterrows():
        with st.container():
            col1, col2 = st.columns([3, 1])
            
            with col1:
                # ì œëª© í‘œì‹œ
                title = row.get('title', '')
                if translation_mode == "í•œêµ­ì–´":
                    st.markdown(f"**{title}**")
                elif translation_mode == "ì˜ì–´":
                    title_en = row.get('title_en', title)
                    st.markdown(f"**{title_en}**")
                else:  # í•œêµ­ì–´+ì˜ì–´
                    st.markdown(f"**{title}**")
                    if 'title_en' in row and row.get('title_en'):
                        st.caption(f"ğŸ‡ºğŸ‡¸ {row.get('title_en', '')}")
                
                # ìš”ì•½ í‘œì‹œ
                summary = row.get('summary', '')
                if len(summary) > 200:
                    summary = summary[:200] + "..."
                st.write(summary)
            
            with col2:
                # ë©”íƒ€ ì •ë³´
                st.write(f"ğŸ“… {row.get('date', '')}")
                st.write(f"ğŸ“° {row.get('source', '')}")
                
                # ë§í¬
                source_url = row.get('source_url', '')
                if source_url and source_url not in ['', 'None']:
                    st.link_button("ğŸ”— ì›ë¬¸", source_url)
                
                # ì¹´í…Œê³ ë¦¬
                categories = row.get('category', [])
                if isinstance(categories, list) and categories:
                    valid_cats = [cat for cat in categories if cat and cat != 'None'][:3]
                    if valid_cats:
                        st.caption(f"ğŸ·ï¸ {', '.join(valid_cats)}")
            
            st.divider()

def typing_effect(text: str, placeholder):
    """íƒ€ì´í•‘ íš¨ê³¼"""
    words = text.split()
    current_text = ""
    
    for i, word in enumerate(words):
        current_text += word + " "
        placeholder.write(current_text)
        if i < len(words) - 1:
            time.sleep(0.03)

# ---------- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ----------
if "user_info" not in st.session_state:
    st.session_state["user_info"] = None

if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# ---------- ì‚¬ìš©ì ì •ë³´ ì…ë ¥ ----------
if st.session_state["user_info"] is None:
    st.title("ğŸ‘‹ í•´ìš´Â·ì² ê°• GPT Assistant")
    st.subheader("ì‚¬ìš©ì ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
    
    col1, col2 = st.columns(2)
    
    with col1:
        groups = st.multiselect(
            "ì†Œì† ê·¸ë£¹",
            options=["steel_export_group", "coal_import_group", "container_group"],
            default=[],
            help="ì†Œì†ëœ ì—…ë¬´ ê·¸ë£¹ì„ ì„ íƒí•˜ì„¸ìš”"
        )
    
    with col2:
        role = st.selectbox(
            "ì§ì±…", 
            options=["ì‚¬ì¥", "ì‹¤ì¥", "ê·¸ë£¹ì¥", "ë¦¬ë”", "ë‹´ë‹¹ì"],
            help="ì§ì±…ì— ë”°ë¼ ë‹µë³€ ìƒì„¸ë„ê°€ ì¡°ì ˆë©ë‹ˆë‹¤"
        )
    
    if st.button("í™•ì¸", type="primary"):
        if groups and role:
            st.session_state["user_info"] = {"groups": groups, "role": role}
            st.rerun()
        else:
            st.error("ê·¸ë£¹ê³¼ ì§ì±…ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    st.stop()

user = st.session_state["user_info"]

# ---------- ì‚¬ì´ë“œë°” ----------
with st.sidebar:
    st.markdown("### ğŸ‘¤ ì‚¬ìš©ì ì •ë³´")
    st.write(f"**ì§ì±…**: {user['role']}")
    st.write(f"**ê·¸ë£¹**: {', '.join(user['groups'])}")
    
    if st.button("ì •ë³´ ë³€ê²½"):
        st.session_state["user_info"] = None
        st.rerun()
    
    st.divider()
    
    # ì‹œìŠ¤í…œ ìƒíƒœ
    st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    
    if META_PATH.exists():
        file_size = META_PATH.stat().st_size / 1024
        st.success(f"âœ… ë°ì´í„°: {file_size:.1f} KB")
    else:
        st.error("âŒ ë°ì´í„° ì—†ìŒ")
    
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key and len(api_key) > 10:
        st.success("âœ… OpenAI ì—°ê²°ë¨")
    else:
        st.warning("âš ï¸ API ë¯¸ì„¤ì •")
    
    st.divider()
    
    # ë¹ ë¥¸ ì•¡ì…˜
    st.markdown("### âš¡ ë¹ ë¥¸ ì•¡ì…˜")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
            st.rerun()
    
    with col2:
        if st.button("ğŸ—‘ï¸ ìºì‹œ ì‚­ì œ"):
            st.cache_data.clear()
            st.success("ì™„ë£Œ!")
            time.sleep(1)
            st.rerun()

# ---------- íƒ­ ë ˆì´ì•„ì›ƒ ----------
tab_dash, tab_chat = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ’¬ ì±—ë´‡"])

# ==== â‘  ëŒ€ì‹œë³´ë“œ ====
with tab_dash:
    st.header("ğŸ“Š ê¸°ì‚¬ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    # ë°ì´í„° ë¡œë”©
    with st.spinner("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘..."):
        df = load_and_clean_metadata()
    
    if df.empty:
        st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”:")
        st.code("python main.py\npython run_embedding_update.py")
        st.stop()
    
    # ê¸°ë³¸ í†µê³„
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ ê¸°ì‚¬", len(df))
    
    with col2:
        unique_sources = df['source'].nunique()
        st.metric("ë‰´ìŠ¤ ì†ŒìŠ¤", unique_sources)
    
    valid_categories, valid_events = get_valid_filter_options(df)
    
    with col3:
        st.metric("ì¹´í…Œê³ ë¦¬", len(valid_categories))
    
    with col4:
        st.metric("ì´ë²¤íŠ¸", len(valid_events))
    
    # í•„í„° ì„¤ì •
    st.subheader("ğŸ” í•„í„° ì„¤ì •")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        date_range = st.date_input(
            "ğŸ“… ë‚ ì§œ ë²”ìœ„",
            value=[],
            help="ì¡°íšŒí•  ë‚ ì§œ ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
    
    with col2:
        available_groups = ["steel_export_group", "coal_import_group", "container_group", "general_group"]
        user_groups = user.get("groups", [])
        group_options = [g for g in available_groups if g in user_groups] if user_groups else available_groups
        
        selected_groups = st.multiselect(
            "ğŸ‘¥ ê·¸ë£¹",
            options=group_options,
            default=user_groups[:1] if user_groups else []
        )
    
    with col3:
        remove_duplicates = st.checkbox("ğŸ”„ ì¤‘ë³µ ì œê±°", value=True)
    
    col4, col5 = st.columns(2)
    
    with col4:
        selected_categories = st.multiselect(
            "ğŸ·ï¸ ì¹´í…Œê³ ë¦¬",
            options=valid_categories,
            help=f"ì´ {len(valid_categories)}ê°œ ì¹´í…Œê³ ë¦¬"
        )
    
    with col5:
        selected_events = st.multiselect(
            "ğŸ“… ì´ë²¤íŠ¸",
            options=valid_events,
            help=f"ì´ {len(valid_events)}ê°œ ì´ë²¤íŠ¸"
        )
    
    # ë²ˆì—­ ì„¤ì •
    st.subheader("ğŸŒ ì–¸ì–´ ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        language_mode = st.radio(
            "í‘œì‹œ ì–¸ì–´",
            options=["í•œêµ­ì–´", "ì˜ì–´", "í•œêµ­ì–´+ì˜ì–´"],
            index=0
        )
    
    with col2:
        auto_translate = st.checkbox(
            "ğŸ”„ ìë™ ë²ˆì—­", 
            value=False,
            help="ì˜ì–´ ê¸°ì‚¬ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­ (ì‹œê°„ ì†Œìš”)"
        )
    
    # í•„í„° ì ìš©
    filters = {
        'date_range': date_range if len(date_range) == 2 else None,
        'groups': selected_groups,
        'categories': selected_categories,
        'events': selected_events
    }
    
    filtered_df = apply_filters(df, filters)
    
    # ì¤‘ë³µ ì œê±°
    if remove_duplicates:
        filtered_df = smart_deduplicate(filtered_df)
    
    # ë²ˆì—­ ì ìš©
    if auto_translate and not filtered_df.empty:
        filtered_df = apply_translation(filtered_df, ['title', 'summary'])
    
    # ê²°ê³¼ í‘œì‹œ
    st.subheader(f"ğŸ“° ê²°ê³¼ ({len(filtered_df)}ê±´)")
    
    if filtered_df.empty:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # í‘œì‹œ ì˜µì…˜
        col1, col2, col3 = st.columns(3)
        
        with col1:
            display_limit = st.selectbox(
                "í‘œì‹œ ê°œìˆ˜",
                options=[10, 25, 50, 100],
                index=1
            )
        
        with col2:
            sort_option = st.selectbox(
                "ì •ë ¬",
                options=["ë‚ ì§œ (ìµœì‹ ìˆœ)", "ë‚ ì§œ (ì˜¤ë˜ëœìˆœ)", "ì œëª©ìˆœ"],
                index=0
            )
        
        with col3:
            view_mode = st.radio(
                "ë³´ê¸° í˜•íƒœ",
                options=["ì¹´ë“œ", "í…Œì´ë¸”"],
                index=0
            )
        
        # ì •ë ¬ ì ìš©
        if sort_option == "ë‚ ì§œ (ìµœì‹ ìˆœ)":
            filtered_df = filtered_df.sort_values('date', ascending=False)
        elif sort_option == "ë‚ ì§œ (ì˜¤ë˜ëœìˆœ)":
            filtered_df = filtered_df.sort_values('date', ascending=True)
        elif sort_option == "ì œëª©ìˆœ":
            filtered_df = filtered_df.sort_values('title', ascending=True)
        
        # ê²°ê³¼ í‘œì‹œ
        if view_mode == "ì¹´ë“œ":
            display_article_cards(filtered_df, language_mode, display_limit)
        else:
            # í…Œì´ë¸” ë³´ê¸°
            display_columns = ["date", "title", "summary", "category", "source", "source_url"]
            if language_mode == "ì˜ì–´" and 'title_en' in filtered_df.columns:
                display_columns = ["date", "title_en", "summary_en", "category", "source", "source_url"]
            
            available_columns = [col for col in display_columns if col in filtered_df.columns]
            
            if available_columns:
                st.dataframe(
                    filtered_df[available_columns].head(display_limit),
                    use_container_width=True,
                    hide_index=True
                )
        
        # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
        col1, col2 = st.columns(2)
        
        with col1:
            csv_data = filtered_df.head(display_limit).to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_data,
                file_name=f"í•´ìš´ë‰´ìŠ¤_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv"
            )
        
        with col2:
            json_data = filtered_df.head(display_limit).to_json(orient='records', force_ascii=False, indent=2)
            st.download_button(
                "ğŸ“¥ JSON ë‹¤ìš´ë¡œë“œ",
                data=json_data,
                file_name=f"í•´ìš´ë‰´ìŠ¤_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
                mime="application/json"
            )

# ==== â‘¡ ì±—ë´‡ ====
with tab_chat:
    st.header("ğŸ’¬ RAG ê¸°ë°˜ í•´ìš´Â·ì² ê°• ì–´ì‹œìŠ¤í„´íŠ¸")
    st.caption(f"ì„¤ì •: {user['role']} | ê·¸ë£¹: {', '.join(user['groups'])}")
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for msg in st.session_state["chat_history"]:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
    
    # ì§ˆë¬¸ ì˜ˆì‹œ
    with st.expander("ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ"):
        examples = [
            "ìµœê·¼ supramax ìš´ì„ ë™í–¥ì€?",
            "iron ore ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ëŠ”?",
            "BDI ì§€ìˆ˜ ë³€í™” ìš”ì¸ì€?",
            "capesize ì„ ë°• ì‹œì¥ ì „ë§ì€?",
            "container shipping ì´ìŠˆëŠ”?"
        ]
        
        for example in examples:
            if st.button(example, key=f"ex_{hash(example)}"):
                st.session_state.example_question = example
    
    # ì§ˆë¬¸ ì…ë ¥
    prompt = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    
    # ì˜ˆì‹œ ì§ˆë¬¸ ì²˜ë¦¬
    if hasattr(st.session_state, 'example_question'):
        prompt = st.session_state.example_question
        delattr(st.session_state, 'example_question')
    
    if prompt:
        # ì‚¬ìš©ì ë©”ì‹œì§€
        with st.chat_message("user"):
            st.write(prompt)
        
        # AI ì‘ë‹µ
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    answer = build_answer(
                        prompt,
                        user_meta={
                            "role": user["role"],
                            "groups": user["groups"],
                            "filters": {}
                        }
                    )
                    
                    # íƒ€ì´í•‘ íš¨ê³¼
                    answer_placeholder = st.empty()
                    typing_effect(answer, answer_placeholder)
                    
                except Exception as e:
                    st.error(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                    answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state["chat_history"].append({"role": "user", "content": prompt})
        st.session_state["chat_history"].append({"role": "assistant", "content": answer})
    
    # ì±„íŒ… ê¸°ë¡ ê´€ë¦¬
    if st.session_state["chat_history"]:
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ—‘ï¸ ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”"):
                st.session_state["chat_history"] = []
                st.rerun()
        
        with col2:
            chat_count = len(st.session_state["chat_history"]) // 2
            st.write(f"ğŸ’¬ ëŒ€í™” ìˆ˜: {chat_count}ê°œ")